"""Vulnerability lookup service — queries NVD for CVEs matching SBOM components.

Scans all SBOM components with CPE identifiers against the NVD API,
stores vulnerability matches, and auto-creates grouped findings with
source='sbom_scan'.
"""

import asyncio
import logging
import uuid
from datetime import datetime

from sqlalchemy import delete, func, select
from sqlalchemy.ext.asyncio import AsyncSession

from app.config import get_settings
from app.models.finding import Finding
from app.models.sbom import SbomComponent, SbomVulnerability

logger = logging.getLogger(__name__)

# NVD rate limits: 0.6 req/s without API key, 6 req/s with key
RATE_LIMIT_NO_KEY = 1.7  # seconds between requests (slightly above 1/0.6)
RATE_LIMIT_WITH_KEY = 0.17  # seconds between requests (slightly above 1/6)
MAX_RETRIES = 3
RETRY_BACKOFF = 5.0  # seconds


def _cvss_to_severity(score: float | None) -> str:
    """Map CVSS score to severity string."""
    if score is None:
        return "medium"
    if score >= 9.0:
        return "critical"
    if score >= 7.0:
        return "high"
    if score >= 4.0:
        return "medium"
    return "low"


def _severity_rank(severity: str) -> int:
    """Rank severity for sorting (higher = more severe)."""
    return {"critical": 4, "high": 3, "medium": 2, "low": 1, "info": 0}.get(
        severity, 0
    )


class VulnerabilityService:
    """Queries NVD for known CVEs matching SBOM components."""

    def __init__(self, db: AsyncSession):
        self.db = db
        settings = get_settings()
        self._api_key = settings.nvd_api_key or None
        self._rate_delay = (
            RATE_LIMIT_WITH_KEY if self._api_key else RATE_LIMIT_NO_KEY
        )

    async def scan_components(
        self,
        firmware_id: uuid.UUID,
        project_id: uuid.UUID,
        force_rescan: bool = False,
    ) -> dict:
        """Scan all SBOM components for known vulnerabilities.

        Returns a summary dict with counts by severity and findings created.
        """
        # Check if scan already done
        if not force_rescan:
            existing_count = await self.db.scalar(
                select(func.count(SbomVulnerability.id)).where(
                    SbomVulnerability.firmware_id == firmware_id
                )
            )
            if existing_count and existing_count > 0:
                return await self._build_summary(firmware_id, cached=True)

        # Clear existing vulns and auto-generated findings if rescanning
        if force_rescan:
            findings_deleted = await self.db.execute(
                delete(Finding).where(
                    Finding.project_id == project_id,
                    Finding.source == "sbom_scan",
                )
            )
            vulns_deleted = await self.db.execute(
                delete(SbomVulnerability).where(
                    SbomVulnerability.firmware_id == firmware_id
                )
            )
            await self.db.flush()
            logger.warning(
                "Force rescan: deleted %d findings, %d vulns",
                findings_deleted.rowcount,
                vulns_deleted.rowcount,
            )

        # Load components with CPE identifiers
        result = await self.db.execute(
            select(SbomComponent).where(
                SbomComponent.firmware_id == firmware_id,
                SbomComponent.cpe.isnot(None),
            )
        )
        components = list(result.scalars().all())

        if not components:
            return {
                "status": "completed",
                "total_components_scanned": 0,
                "total_vulnerabilities_found": 0,
                "findings_created": 0,
                "vulns_by_severity": {},
            }

        # Query NVD for each component
        total_vulns = 0
        for comp in components:
            try:
                vulns_found = await self._query_nvd_for_component(
                    comp, firmware_id
                )
                total_vulns += vulns_found
            except Exception as e:
                logger.warning(
                    "Failed to query NVD for %s %s: %s",
                    comp.name,
                    comp.version,
                    e,
                )

        await self.db.flush()

        # Create grouped findings
        findings_created = await self._create_findings_from_vulns(
            firmware_id, project_id
        )
        await self.db.commit()

        return await self._build_summary(
            firmware_id, findings_created=findings_created
        )

    async def _query_nvd_for_component(
        self,
        component: SbomComponent,
        firmware_id: uuid.UUID,
    ) -> int:
        """Query NVD API for a single component's CPE. Returns count of vulns found."""
        import nvdlib

        cpe = component.cpe
        if not cpe:
            return 0

        vulns_found = 0

        for attempt in range(MAX_RETRIES):
            try:
                await asyncio.sleep(self._rate_delay)

                # Run the synchronous nvdlib call in a thread executor
                loop = asyncio.get_event_loop()
                cves = await loop.run_in_executor(
                    None,
                    lambda: _search_nvd(cpe, self._api_key),
                )

                for cve in cves:
                    if not _cpe_is_vulnerable_in_cve(cve, cpe):
                        continue
                    vuln = self._parse_nvd_cve(cve, component.id, firmware_id)
                    if vuln:
                        self.db.add(vuln)
                        vulns_found += 1

                logger.warning(
                    "NVD %s: %d from API, %d stored",
                    component.name, len(cves), vulns_found,
                )
                return vulns_found

            except Exception as e:
                err_str = str(e).lower()
                if "403" in err_str or "rate" in err_str:
                    # Rate limited — back off and retry
                    wait = RETRY_BACKOFF * (attempt + 1)
                    logger.warning(
                        "NVD rate limited for %s, waiting %.1fs (attempt %d/%d)",
                        component.name,
                        wait,
                        attempt + 1,
                        MAX_RETRIES,
                    )
                    await asyncio.sleep(wait)
                    continue
                else:
                    logger.warning(
                        "NVD query error for %s: %s",
                        component.name,
                        e,
                    )
                    return 0

        logger.warning("NVD query exhausted retries for %s", component.name)
        return 0

    def _parse_nvd_cve(
        self,
        cve,
        component_id: uuid.UUID,
        firmware_id: uuid.UUID,
    ) -> SbomVulnerability | None:
        """Parse an nvdlib CVE result into an SbomVulnerability record."""
        try:
            cve_id = cve.id

            # Extract CVSS score — try v31 first, then v30, then v2
            cvss_score = None
            cvss_vector = None
            if hasattr(cve, "score"):
                # nvdlib provides a score tuple: (version, score, vector)
                score_data = cve.score
                if isinstance(score_data, (list, tuple)) and len(score_data) >= 2:
                    cvss_score = float(score_data[1]) if score_data[1] else None
                    if len(score_data) >= 3:
                        cvss_vector = score_data[2] if score_data[2] else None

            # Extract from metrics if score attribute didn't work
            if cvss_score is None and hasattr(cve, "metrics"):
                metrics = cve.metrics
                if hasattr(metrics, "cvssMetricV31") and metrics.cvssMetricV31:
                    m = metrics.cvssMetricV31[0]
                    cvss_score = m.cvssData.baseScore
                    cvss_vector = m.cvssData.vectorString
                elif hasattr(metrics, "cvssMetricV30") and metrics.cvssMetricV30:
                    m = metrics.cvssMetricV30[0]
                    cvss_score = m.cvssData.baseScore
                    cvss_vector = m.cvssData.vectorString
                elif hasattr(metrics, "cvssMetricV2") and metrics.cvssMetricV2:
                    m = metrics.cvssMetricV2[0]
                    cvss_score = m.cvssData.baseScore
                    cvss_vector = m.cvssData.vectorString

            severity = _cvss_to_severity(cvss_score)

            # Extract description
            description = None
            if hasattr(cve, "descriptions"):
                for desc in cve.descriptions:
                    if hasattr(desc, "lang") and desc.lang == "en":
                        description = desc.value
                        break
                if not description and cve.descriptions:
                    description = cve.descriptions[0].value

            # Extract published date
            published_date = None
            if hasattr(cve, "published"):
                pub = cve.published
                if isinstance(pub, str):
                    try:
                        published_date = datetime.fromisoformat(
                            pub.replace("Z", "+00:00")
                        )
                    except ValueError:
                        pass
                elif isinstance(pub, datetime):
                    published_date = pub

            return SbomVulnerability(
                component_id=component_id,
                firmware_id=firmware_id,
                cve_id=cve_id,
                cvss_score=cvss_score,
                cvss_vector=cvss_vector,
                severity=severity,
                description=description,
                published_date=published_date,
            )

        except Exception as e:
            logger.warning("Failed to parse CVE result: %s", e)
            return None

    async def _create_findings_from_vulns(
        self,
        firmware_id: uuid.UUID,
        project_id: uuid.UUID,
    ) -> int:
        """Create grouped findings from vulnerability scan results.

        Strategy: one finding per component that has critical/high CVEs,
        grouped lower-severity CVEs into fewer findings.
        """
        # Load all vulnerabilities with component info
        stmt = (
            select(SbomVulnerability, SbomComponent)
            .join(SbomComponent, SbomVulnerability.component_id == SbomComponent.id)
            .where(SbomVulnerability.firmware_id == firmware_id)
            .order_by(SbomComponent.name)
        )
        result = await self.db.execute(stmt)
        rows = result.all()

        if not rows:
            return 0

        # Group vulnerabilities by component
        by_component: dict[uuid.UUID, dict] = {}
        for vuln, comp in rows:
            if comp.id not in by_component:
                by_component[comp.id] = {
                    "component": comp,
                    "vulns": [],
                }
            by_component[comp.id]["vulns"].append(vuln)

        findings_created = 0

        for comp_id, data in by_component.items():
            comp = data["component"]
            vulns = data["vulns"]

            # Determine the highest severity
            highest_severity = max(
                (v.severity for v in vulns),
                key=_severity_rank,
            )

            # Only auto-create findings for components with critical/high CVEs
            # or when there are 3+ medium CVEs
            critical_high = [
                v for v in vulns if v.severity in ("critical", "high")
            ]
            medium = [v for v in vulns if v.severity == "medium"]

            if not critical_high and len(medium) < 3:
                continue

            # Build evidence text
            evidence_lines = []
            # Sort vulns by severity then CVE ID
            sorted_vulns = sorted(
                vulns,
                key=lambda v: (-_severity_rank(v.severity), v.cve_id),
            )
            for v in sorted_vulns[:20]:  # Cap at 20 CVEs in evidence
                score_str = f" (CVSS {v.cvss_score})" if v.cvss_score else ""
                desc_str = (
                    f": {v.description[:200]}" if v.description else ""
                )
                evidence_lines.append(
                    f"- [{v.severity.upper()}] {v.cve_id}{score_str}{desc_str}"
                )
            if len(sorted_vulns) > 20:
                evidence_lines.append(
                    f"... and {len(sorted_vulns) - 20} more CVEs"
                )

            cve_ids = [v.cve_id for v in vulns]
            version_str = f" {comp.version}" if comp.version else ""

            finding = Finding(
                project_id=project_id,
                title=f"Known vulnerabilities in {comp.name}{version_str}",
                severity=highest_severity,
                description=(
                    f"SBOM scan identified {len(vulns)} known CVE(s) in "
                    f"{comp.name}{version_str}. This is an inherited "
                    f"vulnerability from a third-party component included "
                    f"in the firmware."
                ),
                evidence="\n".join(evidence_lines),
                file_path=(
                    comp.file_paths[0] if comp.file_paths else None
                ),
                cve_ids=cve_ids,
                source="sbom_scan",
                component_id=comp.id,
            )
            self.db.add(finding)
            await self.db.flush()

            # Link vulnerabilities to the finding
            for v in vulns:
                v.finding_id = finding.id

            findings_created += 1

        return findings_created

    async def _build_summary(
        self,
        firmware_id: uuid.UUID,
        cached: bool = False,
        findings_created: int = 0,
    ) -> dict:
        """Build a vulnerability scan summary dict."""
        # Count vulnerabilities by severity
        stmt = (
            select(
                SbomVulnerability.severity,
                func.count(SbomVulnerability.id),
            )
            .where(SbomVulnerability.firmware_id == firmware_id)
            .group_by(SbomVulnerability.severity)
        )
        result = await self.db.execute(stmt)
        vulns_by_severity = {row[0]: row[1] for row in result.all()}

        total_vulns = sum(vulns_by_severity.values())

        # Count scanned components
        comp_count = await self.db.scalar(
            select(func.count(SbomComponent.id)).where(
                SbomComponent.firmware_id == firmware_id,
                SbomComponent.cpe.isnot(None),
            )
        )

        return {
            "status": "completed" if not cached else "cached",
            "total_components_scanned": comp_count or 0,
            "total_vulnerabilities_found": total_vulns,
            "findings_created": findings_created,
            "vulns_by_severity": vulns_by_severity,
        }

    async def _count_by_resolution(
        self, firmware_id: uuid.UUID
    ) -> tuple[int, int]:
        """Return (open_count, resolved_count) for a firmware's vulns."""
        stmt = (
            select(
                SbomVulnerability.resolution_status,
                func.count(SbomVulnerability.id),
            )
            .where(SbomVulnerability.firmware_id == firmware_id)
            .group_by(SbomVulnerability.resolution_status)
        )
        result = await self.db.execute(stmt)
        counts = {row[0]: row[1] for row in result.all()}
        open_count = counts.get("open", 0)
        resolved_count = (
            counts.get("resolved", 0)
            + counts.get("ignored", 0)
            + counts.get("false_positive", 0)
        )
        return open_count, resolved_count

    async def get_vulnerability_summary(
        self, firmware_id: uuid.UUID
    ) -> dict:
        """Get aggregated vulnerability stats for the SBOM summary endpoint."""
        # Component counts by type
        comp_type_stmt = (
            select(SbomComponent.type, func.count(SbomComponent.id))
            .where(SbomComponent.firmware_id == firmware_id)
            .group_by(SbomComponent.type)
        )
        result = await self.db.execute(comp_type_stmt)
        components_by_type = {row[0]: row[1] for row in result.all()}

        total_components = sum(components_by_type.values())

        # Vuln counts by severity
        vuln_sev_stmt = (
            select(
                SbomVulnerability.severity,
                func.count(SbomVulnerability.id),
            )
            .where(SbomVulnerability.firmware_id == firmware_id)
            .group_by(SbomVulnerability.severity)
        )
        result = await self.db.execute(vuln_sev_stmt)
        vulns_by_severity = {row[0]: row[1] for row in result.all()}
        total_vulns = sum(vulns_by_severity.values())

        # Components with at least one vulnerability
        comps_with_vulns = await self.db.scalar(
            select(func.count(func.distinct(SbomVulnerability.component_id)))
            .where(SbomVulnerability.firmware_id == firmware_id)
        )

        # Most recent scan date
        scan_date = await self.db.scalar(
            select(func.max(SbomVulnerability.created_at)).where(
                SbomVulnerability.firmware_id == firmware_id
            )
        )

        # Resolution counts
        open_count, resolved_count = await self._count_by_resolution(
            firmware_id
        )

        return {
            "total_components": total_components,
            "components_by_type": components_by_type,
            "components_with_vulns": comps_with_vulns or 0,
            "total_vulnerabilities": total_vulns,
            "vulns_by_severity": vulns_by_severity,
            "scan_date": scan_date,
            "open_count": open_count,
            "resolved_count": resolved_count,
        }


def _search_nvd(cpe: str, api_key: str | None) -> list:
    """Query the NVD CVE API directly, bypassing nvdlib.

    nvdlib 0.8.x has a bug where ``isVulnerable=True`` (Python bool) is
    serialised as the string ``"True"`` in the query-string, but the NVD
    API treats ``isVulnerable`` as a valueless boolean flag — any value
    causes a 404.  We make the request ourselves so we can pass the flag
    correctly and still use nvdlib's CVE class for result parsing.
    """
    import requests as _requests
    from nvdlib.classes import CVE

    url = "https://services.nvd.nist.gov/rest/json/cves/2.0"
    # Build query-string manually: isVulnerable must be a bare flag
    qs = f"cpeName={cpe}&isVulnerable"

    headers: dict[str, str] = {}
    if api_key:
        headers["apiKey"] = api_key

    all_cves: list = []
    start_index = 0

    while True:
        page_qs = f"{qs}&startIndex={start_index}"
        resp = _requests.get(url, params=page_qs, headers=headers, timeout=30)
        resp.raise_for_status()
        data = resp.json()

        for item in data.get("vulnerabilities", []):
            cve_data = item.get("cve", item)
            # CVE.__init__ calls vars(self).update(response) so the
            # top level must be a plain dict.  Recursively convert
            # only the *values* to attr-accessible objects so nested
            # attribute access (desc.lang, metrics.cvssMetricV31)
            # works the same way as nvdlib's own pipeline.
            cve_obj = CVE(
                {k: _to_obj(v) for k, v in cve_data.items()}
            )
            cve_obj.getvars()
            all_cves.append(cve_obj)

        total = data.get("totalResults", 0)
        results_per_page = data.get("resultsPerPage", 2000)
        start_index += results_per_page

        if start_index >= total:
            break

        # Respect rate limits between pages
        import time
        time.sleep(1.7 if not api_key else 0.17)

    return all_cves


class _AttrDict:
    """Minimal namespace that allows attribute access on dict data."""

    def __init__(self, d: dict):
        vars(self).update(d)

    def __repr__(self) -> str:
        return repr(vars(self))


def _to_obj(data):
    """Recursively convert dicts to attribute-accessible objects and
    process lists, mirroring how nvdlib converts NVD JSON responses."""
    if isinstance(data, dict):
        return _AttrDict({k: _to_obj(v) for k, v in data.items()})
    if isinstance(data, list):
        return [_to_obj(item) for item in data]
    return data


def _cpe_is_vulnerable_in_cve(cve, queried_cpe: str) -> bool:
    """Check that our CPE is actually *vulnerable* in this CVE.

    Two checks:
    1. The CPE must appear with ``vulnerable=True`` (not just as a
       platform / "runs on" context where ``vulnerable=False``).
    2. If the match entry has version range constraints
       (versionStartIncluding, versionEndExcluding, etc.) our version
       must fall within that range.

    This replaces the NVD ``isVulnerable`` flag (broken in nvdlib 0.8.x)
    with a more thorough client-side check.
    """
    parts = queried_cpe.split(":")
    if len(parts) < 6:
        return True  # malformed CPE, don't filter
    q_part, q_vendor, q_product, q_version = (
        parts[2], parts[3], parts[4], parts[5],
    )

    configurations = getattr(cve, "configurations", None)
    if not configurations:
        return True  # no config data, keep the CVE

    for conf in configurations:
        nodes = getattr(conf, "nodes", None) or []
        for node in nodes:
            if _node_has_vulnerable_match(
                node, q_part, q_vendor, q_product, q_version
            ):
                return True
    return False


def _node_has_vulnerable_match(
    node,
    q_part: str,
    q_vendor: str,
    q_product: str,
    q_version: str,
) -> bool:
    """Recursively check a configuration node for a vulnerable CPE match."""
    cpe_matches = getattr(node, "cpeMatch", None) or []
    for match in cpe_matches:
        if not getattr(match, "vulnerable", False):
            continue
        criteria = getattr(match, "criteria", "")
        m_parts = criteria.split(":")
        if len(m_parts) < 5:
            continue
        if not (
            m_parts[2] == q_part
            and m_parts[3] == q_vendor
            and m_parts[4] == q_product
        ):
            continue

        # Product matches — now check version range constraints
        if _version_in_range(q_version, match):
            return True

    # Check nested children (AND/OR configurations)
    children = getattr(node, "children", None) or []
    for child in children:
        if _node_has_vulnerable_match(
            child, q_part, q_vendor, q_product, q_version
        ):
            return True
    return False


def _parse_version_tuple(version_str: str) -> tuple[int, ...] | None:
    """Parse a dotted version string into a tuple of ints for comparison.

    Returns None if the version can't be parsed (e.g. contains only
    non-numeric segments).  Handles common suffixes like 'rc1' by
    stripping them.
    """
    import re as _re

    # Strip common suffixes: -rc1, .p2, etc.
    cleaned = _re.split(r"[-+_~]", version_str)[0]
    segments = cleaned.split(".")
    nums: list[int] = []
    for seg in segments:
        # Extract leading digits from each segment
        m = _re.match(r"(\d+)", seg)
        if m:
            nums.append(int(m.group(1)))
        else:
            break
    return tuple(nums) if nums else None


def _version_in_range(our_version: str, match) -> bool:
    """Check whether *our_version* falls within the range defined by a
    cpeMatch entry's versionStart/End constraints.

    If no constraints are present the match is unconditional (wildcard).
    """
    # If our CPE has a wildcard version, skip range checking
    if our_version in ("*", "-"):
        return True

    v_start_inc = getattr(match, "versionStartIncluding", None)
    v_start_exc = getattr(match, "versionStartExcluding", None)
    v_end_inc = getattr(match, "versionEndIncluding", None)
    v_end_exc = getattr(match, "versionEndExcluding", None)

    # No range constraints at all — check if the criteria CPE has a
    # specific version that must match exactly
    if not any([v_start_inc, v_start_exc, v_end_inc, v_end_exc]):
        criteria = getattr(match, "criteria", "")
        crit_parts = criteria.split(":")
        if len(crit_parts) >= 6:
            crit_version = crit_parts[5]
            if crit_version not in ("*", "-"):
                # Exact version match required
                return our_version == crit_version
        return True  # wildcard version in criteria, matches everything

    ours = _parse_version_tuple(our_version)
    if ours is None:
        return True  # can't parse our version, keep the CVE to be safe

    # Check start bound
    if v_start_inc:
        bound = _parse_version_tuple(v_start_inc)
        if bound and ours < bound:
            return False
    if v_start_exc:
        bound = _parse_version_tuple(v_start_exc)
        if bound and ours <= bound:
            return False

    # Check end bound
    if v_end_exc:
        bound = _parse_version_tuple(v_end_exc)
        if bound and ours >= bound:
            return False
    if v_end_inc:
        bound = _parse_version_tuple(v_end_inc)
        if bound and ours > bound:
            return False

    return True
